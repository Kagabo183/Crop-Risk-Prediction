"""
Generate real ML-based predictions using XGBoost model and satellite NDVI data
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from datetime import datetime, timedelta
import numpy as np
import joblib
from app.db.database import SessionLocal
from app.models.farm import Farm
from app.models.prediction import Prediction
from app.models.data import SatelliteImage
from app.ml.intelligence import RiskIntelligence
from sqlalchemy import func

def calculate_ndvi_features(farm_id, db, days=30):
    """Calculate NDVI-based features for a farm from satellite images"""
    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=days)
    
    # Get satellite images for this farm from metadata
    images = db.query(SatelliteImage).filter(
        SatelliteImage.date >= start_date,
        SatelliteImage.date <= end_date
    ).all()
    
    # Extract NDVI values for this farm
    ndvi_values = []
    for img in images:
        if img.extra_metadata and img.extra_metadata.get('farm_id') == farm_id:
            ndvi = img.extra_metadata.get('ndvi_value', 0.5)
            ndvi_values.append(ndvi)
    
    # If no specific farm data, use regional average
    if not ndvi_values:
        for img in images:
            if img.extra_metadata:
                ndvi = img.extra_metadata.get('ndvi_value', 0.5)
                ndvi_values.append(ndvi)
    
    # Default if still no data
    if not ndvi_values:
        ndvi_values = [0.65, 0.68, 0.63, 0.70, 0.67]  # Healthy baseline
    
    # Calculate features
    ndvi_array = np.array(ndvi_values)
    
    # NDVI trend (slope over time)
    if len(ndvi_values) > 1:
        x = np.arange(len(ndvi_values))
        ndvi_trend = float(np.polyfit(x, ndvi_array, 1)[0])
    else:
        ndvi_trend = 0.0
    
    # NDVI anomaly (current vs historical mean)
    current_ndvi = ndvi_values[-1]
    historical_mean = 0.70  # Healthy vegetation baseline
    ndvi_anomaly = current_ndvi - historical_mean
    
    # Estimate other features from NDVI
    # Low NDVI suggests drought/water stress
    rainfall_deficit = max(0, (historical_mean - current_ndvi) * 100)  # Scale to mm
    
    # Rapid NDVI decline suggests heat stress
    heat_stress_days = int(abs(min(0, ndvi_trend)) * 100)
    
    return {
        'ndvi_trend': ndvi_trend,
        'ndvi_anomaly': ndvi_anomaly,
        'rainfall_deficit': rainfall_deficit,
        'heat_stress_days': heat_stress_days,
        'current_ndvi': current_ndvi,
        'mean_ndvi': float(np.mean(ndvi_array))
    }

def predict_with_model(features, model_path='crop_stress_xgb_model.pkl'):
    """Use trained model to predict crop stress"""
    try:
        model = joblib.load(model_path)
    except FileNotFoundError:
        print(f"‚ö†Ô∏è  Model file not found: {model_path}")
        print("   Using fallback prediction logic")
        return None
    
    X = np.array([[
        features['ndvi_trend'],
        features['ndvi_anomaly'],
        features['rainfall_deficit'],
        features['heat_stress_days']
    ]])
    
    # Get probability of crop stress (0-1)
    stress_prob = float(model.predict_proba(X)[0][1])
    
    return stress_prob

def generate_ml_predictions(count=50):
    """Generate predictions using ML model and real NDVI data"""
    db = SessionLocal()
    
    # Get all farms
    farms = db.query(Farm).all()
    if not farms:
        print("‚ö†Ô∏è  No farms found. Generate farms first.")
        db.close()
        return []
    
    # Check for satellite images
    image_count = db.query(SatelliteImage).count()
    if image_count == 0:
        print("‚ö†Ô∏è  No satellite images found. Import images first.")
        db.close()
        return []
    
    print(f"\nü§ñ Generating {count} ML-based predictions...")
    print(f"   Using data from {image_count} satellite images")
    
    # Clear old predictions
    existing_count = db.query(Prediction).count()
    if existing_count > 0:
        print(f"üóëÔ∏è  Removing {existing_count} old predictions...")
        db.query(Prediction).delete()
        db.commit()
    
    predictions = []
    base_date = datetime.now() - timedelta(days=30)
    
    for i in range(count):
        farm = farms[i % len(farms)]
        pred_date = base_date + timedelta(days=np.random.randint(0, 30))
        
        # Calculate features from satellite data
        features = calculate_ndvi_features(farm.id, db)
        
        # Use ML model to predict
        stress_prob = predict_with_model(features)
        
        if stress_prob is not None:
            # ML model prediction
            risk_score = stress_prob * 100  # Convert to percentage
            
            # Derive other metrics from NDVI and risk
            # Lower NDVI = higher yield loss
            ndvi_factor = max(0, 1 - features['current_ndvi'])
            yield_loss = risk_score * ndvi_factor * 0.7
            
        else:
            # Fallback: Use NDVI-based heuristics
            current_ndvi = features['current_ndvi']
            
            # NDVI thresholds: <0.3=critical, 0.3-0.5=high, 0.5-0.7=medium, >0.7=low
            if current_ndvi < 0.3:
                risk_score = np.random.uniform(80, 100)
            elif current_ndvi < 0.5:
                risk_score = np.random.uniform(60, 85)
            elif current_ndvi < 0.7:
                risk_score = np.random.uniform(30, 65)
            else:
                risk_score = np.random.uniform(0, 35)
            
            # Add trend influence
            if features['ndvi_trend'] < -0.05:  # Declining vegetation
                risk_score += 15
            
            yield_loss = risk_score * np.random.uniform(0.4, 0.7)
        
        # Clamp values
        risk_score = round(min(100, max(0, risk_score)), 2)
        yield_loss = round(min(100, max(0, yield_loss)), 2)
        
        # Disease risk based on combined factors
        disease_levels = ["Low", "Medium", "High", "Critical"]
        disease_idx = min(3, int(risk_score / 30))
        
        # Increase disease risk if vegetation is declining
        if features['ndvi_trend'] < -0.1:
            disease_idx = min(3, disease_idx + 1)
        
        disease_risk = disease_levels[disease_idx]
        
        # Initialize intelligence engine
        intel = RiskIntelligence()
        
        # Calculate advanced intelligence features
        feature_importance = intel.calculate_feature_importance(features, risk_score)
        top_drivers = intel.get_top_risk_drivers(feature_importance, n=3)
        risk_explanation = intel.explain_risk_drivers(top_drivers, risk_score)
        time_to_impact = intel.calculate_time_to_impact(risk_score, features['ndvi_trend'])
        confidence = intel.calculate_prediction_confidence(features)
        recommendations = intel.generate_recommendations(risk_score, top_drivers, time_to_impact)
        impact_metrics = intel.calculate_impact_metrics(risk_score, yield_loss, farm.area)
        
        # Convert top_drivers list of tuples to dictionary for schema
        risk_drivers_dict = {driver[0]: driver[1] for driver in top_drivers}
        
        prediction = Prediction(
            farm_id=farm.id,
            predicted_at=pred_date,
            risk_score=risk_score,
            yield_loss=yield_loss,
            disease_risk=disease_risk,
            # Advanced intelligence fields
            time_to_impact=time_to_impact,
            confidence_level=confidence['level'],
            confidence_score=confidence['score'],
            risk_drivers=risk_drivers_dict,
            risk_explanation=risk_explanation,
            recommendations=recommendations,
            impact_metrics=impact_metrics
        )
        predictions.append(prediction)
        
        if (i + 1) % 10 == 0:
            print(f"  ‚úì Generated {i + 1}/{count} predictions...")
    
    db.add_all(predictions)
    db.commit()
    
    print(f"\n‚úÖ Generated {count} ML-based predictions with advanced intelligence")
    
    # Show statistics
    avg_risk = sum(p.risk_score for p in predictions) / len(predictions)
    avg_yield_loss = sum(p.yield_loss for p in predictions) / len(predictions)
    high_risk = sum(1 for p in predictions if p.risk_score >= 60)
    immediate_action = sum(1 for p in predictions if p.time_to_impact == "< 7 days")
    
    print(f"\nüìä Prediction Statistics:")
    print(f"  ‚Ä¢ Average Risk Score: {avg_risk:.1f}%")
    print(f"  ‚Ä¢ Average Yield Loss: {avg_yield_loss:.1f}%")
    print(f"  ‚Ä¢ High Risk Farms: {high_risk}/{count}")
    print(f"  ‚Ä¢ Immediate Action Required: {immediate_action}/{count}")
    
    # Show sample predictions
    print(f"\nüìà Sample High-Risk Predictions:")
    samples = sorted(predictions, key=lambda x: x.risk_score, reverse=True)[:5]
    for pred in samples:
        features = calculate_ndvi_features(pred.farm_id, db)
        print(f"\n  Farm {pred.farm_id}:")
        print(f"  ‚Ä¢ Risk: {pred.risk_score:.1f}% | Yield Loss: {pred.yield_loss:.1f}%")
        print(f"  ‚Ä¢ Time to Impact: {pred.time_to_impact}")
        print(f"  ‚Ä¢ Confidence: {pred.confidence_level} ({pred.confidence_score:.0f}%)")
        print(f"  ‚Ä¢ Explanation: {pred.risk_explanation[:100]}...")
    
    db.close()
    return predictions

if __name__ == "__main__":
    print("üöÄ ML-Based Prediction Generator with Advanced Intelligence")
    print("=" * 70)
    generate_ml_predictions(count=50)
